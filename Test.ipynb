{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/daier/anaconda3/envs/testEnv/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1018 17:35:39.563318 4502631872 deprecation_wrapper.py:119] From /Users/daier/anaconda3/envs/testEnv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1018 17:35:39.586373 4502631872 deprecation_wrapper.py:119] From /Users/daier/anaconda3/envs/testEnv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1018 17:35:39.658091 4502631872 deprecation_wrapper.py:119] From /Users/daier/anaconda3/envs/testEnv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1018 17:35:39.658792 4502631872 deprecation_wrapper.py:119] From /Users/daier/anaconda3/envs/testEnv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1018 17:35:39.698024 4502631872 deprecation_wrapper.py:119] From /Users/daier/anaconda3/envs/testEnv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W1018 17:35:39.703814 4502631872 deprecation.py:506] From /Users/daier/anaconda3/envs/testEnv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1018 17:35:39.828878 4502631872 deprecation_wrapper.py:119] From /Users/daier/anaconda3/envs/testEnv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1018 17:35:40.030106 4502631872 deprecation_wrapper.py:119] From /Users/daier/anaconda3/envs/testEnv/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1018 17:35:40.036347 4502631872 deprecation.py:323] From /Users/daier/anaconda3/envs/testEnv/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "from BadWordDetectionByRegularExpression import return_bad_words_index\n",
    "from JamoSplit import jamo_split\n",
    "\n",
    "# model load\n",
    "from gensim.models import FastText\n",
    "from keras.models import load_model\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "embedding_model = FastText.load(\"./gensim_festtext.model\")\n",
    "cnn_model = load_model(\"./cnn_model\")\n",
    "rf_model = joblib.load(\"./rf_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==== 데이터를 input에 넣기 위한 전처리 ===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\"\n",
    "오늘은 2018년이다. 근데 저 18년이 나에게 욕을했다. 엠창 개새끼라고 이것들이 다 욕으로 처리될까요 완전 개새끼구만 오늘 아침에는 18년이 기분이 좋았다 올해 18년 계획은 지금 존나 졸리다 어떡하지 프로그램 미운우리새끼는 욕이 아니고 저 새끼는 욕이겠지 아마 삼시세끼도 똑같겠지? 또 뭐가 있을까요...... ㅋㅋㅋㅋㅋㅋㅋㅋ십알은 어떨까요\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_list = return_bad_words_index(text, mode=1) # 욕설의 형태를 띄는 곳에가서 좌우단어 포함하여 trigram으로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(l, n, trigram_list):\n",
    "        '''\n",
    "        vectroize 할 때 필요한 리스트를 청크별로 나누는 함수\n",
    "        input : list, n(청크 단위)\n",
    "        output : (n개씩 묶어진 list, word_index(단어위치))\n",
    "        '''\n",
    "        for i in range(0, len(l), n):\n",
    "            yield (l[i:i + n], trigram_list[i//n][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('저', '새끼는', '욕이겠지', 32),\n",
       " ('\\n오늘은', '2018년이다.', '근데', 1),\n",
       " ('아마', '삼시세끼도', '똑같겠지?', 35),\n",
       " ('저', '18년이', '나에게', 4),\n",
       " ('욕을했다.', '엠창', '개새끼라고', 7),\n",
       " ('엠창', '개새끼라고', '이것들이', 8),\n",
       " ('완전', '개새끼구만', '오늘', 14),\n",
       " ('아침에는', '18년이', '기분이', 17),\n",
       " ('올해', '18년', '계획은', 21),\n",
       " ('지금', '존나', '졸리다', 24),\n",
       " ('프로그램', '미운우리새끼는', '욕이', 28)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daier/anaconda3/envs/testEnv/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# vectorize : trigram을 150차원의 벡터 + word index형태의 리스트로 만들어주는 과정 \n",
    "trigram_vector = np.array([np.array(embedding_model[jamo_split(word)]) for trigram in trigram_list for word in trigram[:-1]])\n",
    "trigram_vector = np.array(list(chunks(trigram_vector, 3, trigram_list))) # 50차원의 3개의 vector가 1개의 trigram에 들어가기위해 나눠주는 과정\n",
    "trigram_vector = np.array([np.append(_[0].flatten(), _[1]) for _ in trigram_vector]) # 3 x 50 을 150차원으로 flatten + word index = 151dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 151)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = np.int8(trigram_vector[:, -1]) # word_index 단어위치를 뽑아내기\n",
    "trigram_vector = np.delete(trigram_vector, -1, axis=1) # word_index 지우기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==== 결과 확인 ====\n",
    "# ==== CNN ===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_vector = trigram_vector.reshape(trigram_vector.shape[0], trigram_vector.shape[1], 1) # keras input 맞춰주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 150, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어위치\n",
      " [32  1 35  4  7  8 14 17 21 24 28]\n",
      "예측 확률 값\n",
      " [[0.9957671 ]\n",
      " [0.62791127]\n",
      " [0.70563596]\n",
      " [0.98375434]\n",
      " [0.99994034]\n",
      " [0.9999865 ]\n",
      " [0.9995563 ]\n",
      " [0.9997824 ]\n",
      " [0.00102557]\n",
      " [0.9999993 ]\n",
      " [0.9139524 ]]\n",
      "Class와 단어 위치\n",
      " [(True, 32), (False, 1), (True, 35), (True, 4), (True, 7), (True, 8), (True, 14), (True, 17), (False, 21), (True, 24), (True, 28)]\n"
     ]
    }
   ],
   "source": [
    "# cnn\n",
    "print(\"단어위치\\n\", word_index)\n",
    "print(\"예측 확률 값\\n\", cnn_model.predict(trigram_vector))\n",
    "result = cnn_model.predict(trigram_vector) > 0.65 # 0.65보다 높으면 욕설\n",
    "result = result.reshape(-1).tolist()\n",
    "print(\"Class와 단어 위치\\n\", list(zip(result, word_index.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "비속어\n",
      " [['저' '새끼는' '욕이겠지' '32']\n",
      " ['아마' '삼시세끼도' '똑같겠지?' '35']\n",
      " ['저' '18년이' '나에게' '4']\n",
      " ['욕을했다.' '엠창' '개새끼라고' '7']\n",
      " ['엠창' '개새끼라고' '이것들이' '8']\n",
      " ['완전' '개새끼구만' '오늘' '14']\n",
      " ['아침에는' '18년이' '기분이' '17']\n",
      " ['지금' '존나' '졸리다' '24']\n",
      " ['프로그램' '미운우리새끼는' '욕이' '28']]\n",
      "비속어 아닌것들\n",
      " [['\\n오늘은' '2018년이다.' '근데' '1']\n",
      " ['올해' '18년' '계획은' '21']]\n"
     ]
    }
   ],
   "source": [
    "# 결과 확인\n",
    "print(\"비속어\\n\", np.array(trigram_list)[np.array(result)])\n",
    "print(\"비속어 아닌것들\\n\", np.array(trigram_list)[np.array(result) == False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==== RandomForest ===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_vector = trigram_vector.reshape(trigram_vector.shape[0], trigram_vector.shape[1]) # random forest input 맞춰주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어위치\n",
      " [32  1 35  4  7  8 14 17 21 24 28]\n",
      "예측 확률 값\n",
      " [[0.3375 0.6625]\n",
      " [0.275  0.725 ]\n",
      " [0.35   0.65  ]\n",
      " [0.3125 0.6875]\n",
      " [0.125  0.875 ]\n",
      " [0.1125 0.8875]\n",
      " [0.2    0.8   ]\n",
      " [0.1875 0.8125]\n",
      " [0.6125 0.3875]\n",
      " [0.0875 0.9125]\n",
      " [0.325  0.675 ]]\n",
      "Class와 단어 위치\n",
      " [(True, 32), (True, 1), (False, 35), (True, 4), (True, 7), (True, 8), (True, 14), (True, 17), (False, 21), (True, 24), (True, 28)]\n"
     ]
    }
   ],
   "source": [
    "# randomforest\n",
    "print(\"단어위치\\n\", word_index)\n",
    "print(\"예측 확률 값\\n\", rf_model.predict_proba(trigram_vector))\n",
    "result = rf_model.predict_proba(trigram_vector)[:, 1] > 0.65 # 0.65보다 높으면 욕설\n",
    "result = result.tolist()\n",
    "# result = [_==1 for _ in result] # Boolean list로 만들기\n",
    "print(\"Class와 단어 위치\\n\", list(zip(result, word_index.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "비속어\n",
      " [['저' '새끼는' '욕이겠지' '32']\n",
      " ['\\n오늘은' '2018년이다.' '근데' '1']\n",
      " ['저' '18년이' '나에게' '4']\n",
      " ['욕을했다.' '엠창' '개새끼라고' '7']\n",
      " ['엠창' '개새끼라고' '이것들이' '8']\n",
      " ['완전' '개새끼구만' '오늘' '14']\n",
      " ['아침에는' '18년이' '기분이' '17']\n",
      " ['지금' '존나' '졸리다' '24']\n",
      " ['프로그램' '미운우리새끼는' '욕이' '28']]\n",
      "비속어 아닌것들\n",
      " [['아마' '삼시세끼도' '똑같겠지?' '35']\n",
      " ['올해' '18년' '계획은' '21']]\n"
     ]
    }
   ],
   "source": [
    "# 결과 확인\n",
    "print(\"비속어\\n\", np.array(trigram_list)[np.array(result)])\n",
    "print(\"비속어 아닌것들\\n\", np.array(trigram_list)[np.array(result) == False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
